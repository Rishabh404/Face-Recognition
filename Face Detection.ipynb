{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PIL** is the python image library that will easily display the image on the screen and draw lines on top of the image. We will use it to display the result to our face detection code.\n",
    "\n",
    "**face_recognition**: This is the library to give us access to face detection model in dlib. To perform face detection with this library, we just need to load an image file and then run the image file through the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PIL.Image\n",
    "import PIL.ImageDraw\n",
    "import face_recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use pre-trained **HOG face detector** to detect all the faces that appear in an image. Because all the faces are of roughly the same structure, the pretrained model will work well with almost any image. There is no need to train a new one from scratch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the jpg file into a numpy array - We are loading the image file here\n",
    "# people.jpg image file is present in our workspace. It consists of an image of a group of people whose faces we wish \n",
    "# to detect. To load the image into memory, we need to call face_recognition's load_image_file function\n",
    "image = face_recognition.load_image_file('people.jpg')\n",
    "# The above code loads the image into an array where each pixel in the image is an element in the array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        ...,\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255]],\n",
       "\n",
       "       [[255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        ...,\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255]],\n",
       "\n",
       "       [[255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        ...,\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[199, 216, 223],\n",
       "        [200, 217, 224],\n",
       "        [200, 217, 224],\n",
       "        ...,\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255]],\n",
       "\n",
       "       [[199, 216, 223],\n",
       "        [200, 217, 224],\n",
       "        [201, 218, 225],\n",
       "        ...,\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255]],\n",
       "\n",
       "       [[199, 216, 223],\n",
       "        [201, 218, 225],\n",
       "        [202, 219, 226],\n",
       "        ...,\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255]]], dtype=uint8)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can run the **pre-trained HOG face detector** by calling the face_locations function in the face_recognition library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find all the faces in the image\n",
    "face_locations = face_recognition.face_locations(image)\n",
    "# To use the above function, we have passsed in the array of image data\n",
    "# The function will return the list of faces found in the image. If no faces our found, it will return an empty list. \n",
    "# Otherwise there will be one entry in the list for each face that is found."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each face that is returned will contain **four points**. Those points are the pixel locations of the face in the image given as **top**, **right**, **bottom** and **left** coordinates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(163, 605, 271, 497),\n",
       " (186, 364, 275, 275),\n",
       " (211, 175, 319, 67),\n",
       " (295, 760, 402, 653),\n",
       " (271, 474, 378, 366),\n",
       " (152, 832, 259, 724)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "face_locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I found 6 face(s) in this photograph.\n"
     ]
    }
   ],
   "source": [
    "# Checking size of the list to print how many faces were found in the image\n",
    "number_of_faces = len(face_locations)\n",
    "print('I found {} face(s) in this photograph.'.format(number_of_faces))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To be able to see where the faces are visually in the image, we would want to **display image on the screen** and **draw a box on top of it**. Using **PIL** library, we would be able to achieve this objective.\n",
    "\n",
    "The **PIL** library works with the **images** that are in its own **internal format**. So, we need to **convert** our **image array** into a **PIL formatted image**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the image into a Python Image Library object so that we can draw on top of it and display it\n",
    "pil_image = PIL.Image.fromarray(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each face location is a set of coordinates where the face appears in the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A face is located at pixel location Top: 163, Left: 497, Bottom: 271, Right: 605\n",
      "A face is located at pixel location Top: 186, Left: 275, Bottom: 275, Right: 364\n",
      "A face is located at pixel location Top: 211, Left: 67, Bottom: 319, Right: 175\n",
      "A face is located at pixel location Top: 295, Left: 653, Bottom: 402, Right: 760\n",
      "A face is located at pixel location Top: 271, Left: 366, Bottom: 378, Right: 474\n",
      "A face is located at pixel location Top: 152, Left: 724, Bottom: 259, Right: 832\n"
     ]
    }
   ],
   "source": [
    "# Looping through list of faces to see the location of each one\n",
    "for face_location in face_locations:\n",
    "    # Print the location of each face in this image. Each face is a list of co-ordinates in (top, right, bottom, left) order.\n",
    "    top, right, bottom, left = face_location\n",
    "    print('A face is located at pixel location Top: {}, Left: {}, Bottom: {}, Right: {}'.format(top, left, bottom, right))\n",
    "    # Let's draw a box around the face\n",
    "    draw = PIL.ImageDraw.Draw(pil_image)\n",
    "    draw.rectangle([left, top, right, bottom], outline=\"red\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the image on screen\n",
    "pil_image.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
